################################################################
#Pre-Processing Data
#Removing the line breaks
songs.v <- paste(text.v, collapse = " ")
head(songs.v)
#Making words lower case
songs.lower.v <- tolower(songs.v)
songs.lower.v
#Producing a list of words
song.words.l <- strsplit(songs.lower.v, "\\W")
song.words.l
#Unlisting a word
song.word.v <- unlist(song.words.l)
song.word.v
#Keeping only the non-blanks
not.blanks.v <- which(song.word.v != "")
song.word.v <- song.word.v[not.blanks.v]
#Removing sight words
not.sight.words <- which(song.word.v != "oh" &
song.word.v != "a" &
song.word.v != "tu" &
song.word.v != "you" &
song.word.v != "to" &
song.word.v != "de" &
song.word.v != "u" &
song.word.v != "que" &
song.word.v != "is" &
song.word.v != "my" &
song.word.v != "your" &
song.word.v != "ti" &
song.word.v != "we" &
song.word.v != "la" &
song.word.v != "coro" &
song.word.v != "en" &
song.word.v != "me" &
song.word.v != "mi" &
song.word.v != "y" &
song.word.v != "on" &
song.word.v != "the" &
song.word.v != "lo" &
song.word.v != "and" &
song.word.v != "tú" &
song.word.v != "with" &
song.word.v != "o" &
song.word.v != "verso" &
song.word.v != "has" &
song.word.v != "s" &
song.word.v != "tú" &
song.word.v != "with" &
song.word.v != "sofi" &
song.word.v != "por" &
song.word.v != "for" &
song.word.v != "of" &
song.word.v != "it" &
song.word.v != "al" &
song.word.v != "un" &
song.word.v != "se" &
song.word.v != "por" &
song.word.v != "for" &
song.word.v != "chorus")
song.word.v <- song.word.v[not.sight.words]
head(song.word.v)
################################################################
#Starting Analysis
#Counting the word heart and the calculating a frequency of the word
length(song.word.v[which(song.word.v=="heart")])/length((song.word.v))
#Counting the number of unique words used in the album
length(unique(song.word.v))
#Unique words as a percentage of all words
length(unique(song.word.v))/length(song.word.v)
#Favorite words in songs
song.freq.t <- table(song.word.v)
sorted.song.freq.t <- sort(song.freq.t, decreasing = TRUE)
sorted.song.freq.t
################################################################
#Comparing Word Frequency in the Data
#How gender bias are the songs
sorted.song.freq.t["him"]/sorted.song.freq.t["her"]
#Calculating the relative frequency
sorted.song.rel.freqs.t <- 100*(sorted.song.freq.t/sum(sorted.song.freq.t))
#Top 10 Words
plot(sorted.song.rel.freqs.t[1:20], type = "b",
xlab = "Top Twenty Words", ylab = "Percentage of Quiero Adorar", xaxt = "n")
axis(1, 1: 20, labels = names(sorted.song.rel.freqs.t[1:20]))
song.word.v
song.word.v["lips"]
song.word.v["lip"]
song.word.v["mouth"]
song.word.v["lord"]
song.word.v
song.word.v['touching']
sorted.song.freq.t
sorted.song.freq.t[won]
sorted.song.freq.t["won"]
sorted.song.freq.t["lip"]
sorted.song.freq.t["lips"]
sorted.song.freq.t
sorted.song.freq.t["labios"]
song.word['labios']
song.words.l['labios']
song.words.l[['labios']]
sorted.song.freq.t["labios"]
################################################################
#Importing Songs
setwd("~/Documents/Text Analysis of Quiero Adorar/Quiero-Adorar")
#Finding start of new songs
rm(list = ls())
song.v <- scan("Songs.txt", what = "character", sep = "\n")
song.position <- grep("^SONG:", song.v)
song.v[song.position]
#Adding a new line to songs to identify the end of the document.
song.v <- c(song.v, "END")
last.position <- length(song.v)
song.position <- c(song.position, last.position)
#Creating two lists to store results or raw frequencies and relative frequencies
song.raws.l <- list()
song.freqs.l <- list()
for(i in 1:length(song.position)){#initiates a for loop that iterates over song position
if (i != length(song.position)){#Stopping loop at end of document
#Preparing the Data
song.title <- song.v[song.position[i]] #Capturing the song title
start <- song.position[i] + 1 #Adding 1 to position to get first line of song
end <- song.position[i + 1] - 1#Getting last line of a song
#Similar to analysis done in first analysis 1. First Initial...
song.lines.v <- song.v[start:end]
song.words.v <- tolower(paste(song.lines.v, collapse = " "))
song.words.l <- strsplit(song.words.v, "\\W")
song.words.v <- unlist(song.words.l)
song.words.v <- song.words.v[which(song.words.v != "")]
#Removing commong sight words
#Removing sight words
not.sight.words <- which(song.words.v != "oh" &
song.words.v != "a" &
song.words.v != "tu" &
song.words.v != "you" &
song.words.v != "to" &
song.words.v != "de" &
song.words.v != "u" &
song.words.v != "que" &
song.words.v != "is" &
song.words.v != "my" &
song.words.v != "your" &
song.words.v != "ti" &
song.words.v != "we" &
song.words.v != "la" &
song.words.v != "coro" &
song.words.v != "en" &
song.words.v != "me" &
song.words.v != "mi" &
song.words.v != "y" &
song.words.v != "on" &
song.words.v != "the" &
song.words.v != "lo" &
song.words.v != "and" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "o" &
song.words.v != "verso" &
song.words.v != "has" &
song.words.v != "s" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "sofi" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "of" &
song.words.v != "it" &
song.words.v != "al" &
song.words.v != "un" &
song.words.v != "se" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "chorus")
song.words.v <- song.words.v[not.sight.words]
#Creating Frequency Tables
song.freqs.t <- table(song.words.v)
song.raws.l[[song.title]] <- song.freqs.t
song.freqs.t.rel <- 100*(song.freqs.t/sum(song.freqs.t))
song.freqs.l[[song.title]] <- song.freqs.t.rel
}
}
song.freqs.l
song.freqs.l[[1]]
song.freqs.l[[1]]['quiero']
lapply(song.freqs.l, '[', 'quiero')
quiero <- lapply(song.freqs.l, '[', 'quiero')
lapply(song.freqs.l, '[', 'quiero')
quiero.l <- lapply(song.freqs.l, '[', 'quiero')
do.call(rbind,quiero.l)
song.freqs.l
#Applying the subset function to the relative frequency of a word in each song
quiero.l <- lapply(song.freqs.l, '[', 'quiero')
senor.l <- lapply(song.freqs.l, '[', 'señor')
#Rbinding all the list to get a matrix with all the data
do.call(rbind,quiero.l)
do.call(rbind,senor.l)
song.m
#Rbinding all the list to get a matrix with all the data
quiero.m <- do.call(rbind,quiero.l)
senor.m <- do.call(rbind,senor.l)
senor.m
senor.m[,1]
quiero.v <- quiero[,1]
quiero.v <- quiero.m[,1]
senor.v <- senor.m[,1]
cbind(quiero.v, senor.v)
colnames(quiero.senor.m) <- c("quiero", "senor")
quiero.senor.m <- cbind(quiero.v, senor.v)
#Renaming columns above
colnames(quiero.senor.m) <- c("quiero", "senor")
quiero.senor.m
barplot(quiero.senor.m, beside = TRUE, col = 'grey')
barplot(quiero.senor.m, beside = TRUE, col = 'red')
################################################################
#Importing Songs
setwd("~/Documents/Text Analysis of Quiero Adorar/Quiero-Adorar")
text.v <- scan("Songs.txt", what = "character", sep = "\n")
head(text.v)
################################################################
#Pre-Processing Data
#Removing the line breaks
songs.v <- paste(text.v, collapse = " ")
head(songs.v)
#Making words lower case
songs.lower.v <- tolower(songs.v)
songs.lower.v
#Producing a list of words
song.words.l <- strsplit(songs.lower.v, "\\W")
song.words.l
#Unlisting a word
song.word.v <- unlist(song.words.l)
song.word.v
#Keeping only the non-blanks
not.blanks.v <- which(song.word.v != "")
song.word.v <- song.word.v[not.blanks.v]
#Removing sight words
not.sight.words <- which(song.word.v != "oh" &
song.word.v != "a" &
song.word.v != "tu" &
song.word.v != "you" &
song.word.v != "to" &
song.word.v != "de" &
song.word.v != "u" &
song.word.v != "que" &
song.word.v != "is" &
song.word.v != "my" &
song.word.v != "your" &
song.word.v != "ti" &
song.word.v != "we" &
song.word.v != "la" &
song.word.v != "coro" &
song.word.v != "en" &
song.word.v != "me" &
song.word.v != "mi" &
song.word.v != "y" &
song.word.v != "on" &
song.word.v != "the" &
song.word.v != "lo" &
song.word.v != "and" &
song.word.v != "tú" &
song.word.v != "with" &
song.word.v != "o" &
song.word.v != "verso" &
song.word.v != "has" &
song.word.v != "s" &
song.word.v != "tú" &
song.word.v != "with" &
song.word.v != "sofi" &
song.word.v != "por" &
song.word.v != "for" &
song.word.v != "of" &
song.word.v != "it" &
song.word.v != "al" &
song.word.v != "un" &
song.word.v != "se" &
song.word.v != "por" &
song.word.v != "for" &
song.word.v != "chorus")
song.word.v <- song.word.v[not.sight.words]
head(song.word.v)
################################################################
#Starting Analysis
#Counting the word heart and the calculating a frequency of the word
length(song.word.v[which(song.word.v=="heart")])/length((song.word.v))
#Counting the number of unique words used in the album
length(unique(song.word.v))
#Unique words as a percentage of all words
length(unique(song.word.v))/length(song.word.v)
#Favorite words in songs
song.freq.t <- table(song.word.v)
sorted.song.freq.t <- sort(song.freq.t, decreasing = TRUE)
sorted.song.freq.t
################################################################
#Comparing Word Frequency in the Data
#How gender bias are the songs
sorted.song.freq.t["him"]/sorted.song.freq.t["her"]
#Calculating the relative frequency
sorted.song.rel.freqs.t <- 100*(sorted.song.freq.t/sum(sorted.song.freq.t))
#Top 10 Words
plot(sorted.song.rel.freqs.t[1:20], type = "b",
xlab = "Top Twenty Words", ylab = "Percentage of Quiero Adorar", xaxt = "n")
axis(1, 1: 20, labels = names(sorted.song.rel.freqs.t[1:20]))
################################################################
#Token Distribution Analysis
#Creating a sequence the length of the text
n.time.v <- seq(1:length(song.word.v))
#Create a vector for the occurance of 'quiero', standardized for the length of the texrt
quiero.v <- which(song.word.v == 'quiero')
w.count.v <- rep(NA, length(n.time.v))
w.count.v[quiero.v] <- 1
plot(w.count.v, main = "Dispersion Plot of 'quiero' in Quiero Adorar",
xlab = "Album Time", ylab = "quiero", type = "h", ylim = c(0,1), yaxt = 'n')
song.freq.t
################################################################
#Importing Songs
setwd("~/Documents/Text Analysis of Quiero Adorar/Quiero-Adorar")
text.v <- scan("Songs.txt", what = "character", sep = "\n")
head(text.v)
################################################################
#Pre-Processing Data
#Removing the line breaks
songs.v <- paste(text.v, collapse = " ")
head(songs.v)
#Making words lower case
songs.lower.v <- tolower(songs.v)
songs.lower.v
#Producing a list of words
song.words.l <- strsplit(songs.lower.v, "\\W")
song.words.l
#Unlisting a word
song.word.v <- unlist(song.words.l)
song.word.v
#Keeping only the non-blanks
not.blanks.v <- which(song.word.v != "")
song.word.v <- song.word.v[not.blanks.v]
#Removing sight words
not.sight.words <- which(song.word.v != "oh" &
song.word.v != "a" &
song.word.v != "tu" &
song.word.v != "you" &
song.word.v != "to" &
song.word.v != "de" &
song.word.v != "u" &
song.word.v != "que" &
song.word.v != "is" &
song.word.v != "my" &
song.word.v != "your" &
song.word.v != "ti" &
song.word.v != "we" &
song.word.v != "la" &
song.word.v != "coro" &
song.word.v != "en" &
song.word.v != "me" &
song.word.v != "mi" &
song.word.v != "y" &
song.word.v != "on" &
song.word.v != "the" &
song.word.v != "lo" &
song.word.v != "and" &
song.word.v != "tú" &
song.word.v != "with" &
song.word.v != "o" &
song.word.v != "verso" &
song.word.v != "has" &
song.word.v != "s" &
song.word.v != "tú" &
song.word.v != "with" &
song.word.v != "sofi" &
song.word.v != "por" &
song.word.v != "for" &
song.word.v != "of" &
song.word.v != "it" &
song.word.v != "al" &
song.word.v != "un" &
song.word.v != "se" &
song.word.v != "por" &
song.word.v != "for" &
song.word.v != "chorus")
song.word.v <- song.word.v[not.sight.words]
head(song.word.v)
################################################################
#Starting Analysis
#Counting the word heart and the calculating a frequency of the word
length(song.word.v[which(song.word.v=="heart")])/length((song.word.v))
#Counting the number of unique words used in the album
length(unique(song.word.v))
#Unique words as a percentage of all words
length(unique(song.word.v))/length(song.word.v)
#Favorite words in songs
song.freq.t <- table(song.word.v)
sorted.song.freq.t <- sort(song.freq.t, decreasing = TRUE)
sorted.song.freq.t
################################################################
#Comparing Word Frequency in the Data
#How gender bias are the songs
sorted.song.freq.t["him"]/sorted.song.freq.t["her"]
#Calculating the relative frequency
sorted.song.rel.freqs.t <- 100*(sorted.song.freq.t/sum(sorted.song.freq.t))
#Top 10 Words
plot(sorted.song.rel.freqs.t[1:20], type = "b",
xlab = "Top Twenty Words", ylab = "Percentage of Quiero Adorar", xaxt = "n")
axis(1, 1: 20, labels = names(sorted.song.rel.freqs.t[1:20]))
################################################################
#Token Distribution Analysis
#Creating a sequence the length of the text
n.time.v <- seq(1:length(song.word.v))
#Create a vector for the occurance of 'quiero', standardized for the length of the texrt
quiero.v <- which(song.word.v == 'quiero')
w.count.v <- rep(NA, length(n.time.v))
w.count.v[quiero.v] <- 1
plot(w.count.v, main = "Dispersion Plot of 'quiero' in Quiero Adorar",
xlab = "Album Time", ylab = "quiero", type = "h", ylim = c(0,1), yaxt = 'n')
#Finding start of new songs
rm(list = ls())
song.v <- scan("Songs.txt", what = "character", sep = "\n")
song.position <- grep("^SONG:", song.v)
song.v[song.position]
################################################################
#Importing Songs
setwd("~/Documents/Text Analysis of Quiero Adorar/Quiero-Adorar")
#Finding start of new songs
rm(list = ls())
song.v <- scan("Songs.txt", what = "character", sep = "\n")
song.position <- grep("^SONG:", song.v)
song.v[song.position]
#Adding a new line to songs to identify the end of the document.
song.v <- c(song.v, "END")
last.position <- length(song.v)
song.position <- c(song.position, last.position)
#Creating two lists to store results or raw frequencies and relative frequencies
song.raws.l <- list()
song.freqs.l <- list()
for(i in 1:length(song.position)){#initiates a for loop that iterates over song position
if (i != length(song.position)){#Stopping loop at end of document
#Preparing the Data
song.title <- song.v[song.position[i]] #Capturing the song title
start <- song.position[i] + 1 #Adding 1 to position to get first line of song
end <- song.position[i + 1] - 1#Getting last line of a song
#Similar to analysis done in first analysis 1. First Initial...
song.lines.v <- song.v[start:end]
song.words.v <- tolower(paste(song.lines.v, collapse = " "))
song.words.l <- strsplit(song.words.v, "\\W")
song.words.v <- unlist(song.words.l)
song.words.v <- song.words.v[which(song.words.v != "")]
#Removing commong sight words
#Removing sight words
not.sight.words <- which(song.words.v != "oh" &
song.words.v != "a" &
song.words.v != "tu" &
song.words.v != "you" &
song.words.v != "to" &
song.words.v != "de" &
song.words.v != "u" &
song.words.v != "que" &
song.words.v != "is" &
song.words.v != "my" &
song.words.v != "your" &
song.words.v != "ti" &
song.words.v != "we" &
song.words.v != "la" &
song.words.v != "coro" &
song.words.v != "en" &
song.words.v != "me" &
song.words.v != "mi" &
song.words.v != "y" &
song.words.v != "on" &
song.words.v != "the" &
song.words.v != "lo" &
song.words.v != "and" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "o" &
song.words.v != "verso" &
song.words.v != "has" &
song.words.v != "s" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "sofi" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "of" &
song.words.v != "it" &
song.words.v != "al" &
song.words.v != "un" &
song.words.v != "se" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "chorus")
song.words.v <- song.words.v[not.sight.words]
#Creating Frequency Tables
song.freqs.t <- table(song.words.v)
song.raws.l[[song.title]] <- song.freqs.t
song.freqs.t.rel <- 100*(song.freqs.t/sum(song.freqs.t))
song.freqs.l[[song.title]] <- song.freqs.t.rel
}
}
###################################################
#Begining of listwise analysis
#Applying the subset function to the relative frequency of a word in each song
quiero.l <- lapply(song.freqs.l, '[', 'quiero')
adorar.l <- lapply(song.freqs.l, '[', 'adorar')
#Rbinding all the list to get a matrix with all the data
quiero.m <- do.call(rbind,quiero.l)
adorar.m <- do.call(rbind,adorar.l)
#Pulling frequency vectors out to combine two frequencies
quiero.v <- quiero.m[,1]
adorar.v <- adorar.m[,1]
quiero.adorar.m <- cbind(quiero.v, adorar.v)
#Renaming columns above
colnames(quiero.adorar.m) <- c("quiero", "adorar")
#Creating a barplot of the two words
barplot(quiero.adorar.m, beside = TRUE, col = 'red')
