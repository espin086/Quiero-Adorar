################################################################
#Importing data from Github
library(RCurl)
library(foreign)
url <- "https://docs.google.com/spreadsheets/d/1PnApS78YiDPaMnRpkZM2Z19tBIJSVkR6XfWrtACGAl4/pub?output=csv"
room.mates <- getURL(url)
room.mates <- read.csv(textConnection(room.mates), header = TRUE, skip =0)
url2 <- "https://docs.google.com/spreadsheets/d/1Kg7ceTcX6C8MLYHuWkDSFJWgvKqI_b5bJpP-6Zbj9aM/pub?output=csv"
chores <- getURL(url2)
chores <- read.csv(textConnection(chores), header = TRUE, skip =0)
View(chores)
View(room.mates)
#Calculating how good person 1 is at each chore.
p1.c1 <- sum(room.mates[1,2:4] - chores[1,2:4])
p1.c2 <- sum(room.mates[1,2:4] - chores[2,2:4])
p1.c3 <- sum(room.mates[1,2:4] - chores[3,2:4])
p1 <- rbind(c(p1.c1, p1.c2, p1.c3))
#Calculating how good person 2 is at each chore.
p2.c1 <- sum(room.mates[2,2:4] - chores[1,2:4])
p2.c2 <- sum(room.mates[2,2:4] - chores[2,2:4])
p2.c3 <- sum(room.mates[2,2:4] - chores[3,2:4])
p2 <- rbind(c(p2.c1, p2.c2, p2.c3))
#Calculating how good person 3 is at each chore.
p3.c1 <- sum(room.mates[3,2:4] - chores[1,2:4])
p3.c2 <- sum(room.mates[3,2:4] - chores[2,2:4])
p3.c3 <- sum(room.mates[3,2:4] - chores[3,2:4])
p3 <- rbind(c(p3.c1, p3.c2, p3.c3))
#Combining person-chore 'cost' matrix
final <- rbind(p1, p2, p3)
View(final)
#Solving the Assignment Problem
answer <- lp.assign(final, direction = "min")
answer$solution
answer <- lp.assign(final, direction = "min")
################################################################
#Importing data from Github
library(RCurl)
library(foreign)
library(linprog)
url <- "https://docs.google.com/spreadsheets/d/1PnApS78YiDPaMnRpkZM2Z19tBIJSVkR6XfWrtACGAl4/pub?output=csv"
room.mates <- getURL(url)
room.mates <- read.csv(textConnection(room.mates), header = TRUE, skip =0)
url2 <- "https://docs.google.com/spreadsheets/d/1Kg7ceTcX6C8MLYHuWkDSFJWgvKqI_b5bJpP-6Zbj9aM/pub?output=csv"
chores <- getURL(url2)
chores <- read.csv(textConnection(chores), header = TRUE, skip =0)
################################################################
#Calculating how good person 1 is at each chore.
p1.c1 <- sum(room.mates[1,2:4] - chores[1,2:4])
p1.c2 <- sum(room.mates[1,2:4] - chores[2,2:4])
p1.c3 <- sum(room.mates[1,2:4] - chores[3,2:4])
p1 <- rbind(c(p1.c1, p1.c2, p1.c3))
#Calculating how good person 2 is at each chore.
p2.c1 <- sum(room.mates[2,2:4] - chores[1,2:4])
p2.c2 <- sum(room.mates[2,2:4] - chores[2,2:4])
p2.c3 <- sum(room.mates[2,2:4] - chores[3,2:4])
p2 <- rbind(c(p2.c1, p2.c2, p2.c3))
#Calculating how good person 3 is at each chore.
p3.c1 <- sum(room.mates[3,2:4] - chores[1,2:4])
p3.c2 <- sum(room.mates[3,2:4] - chores[2,2:4])
p3.c3 <- sum(room.mates[3,2:4] - chores[3,2:4])
p3 <- rbind(c(p3.c1, p3.c2, p3.c3))
#Combining person-chore 'cost' matrix
final <- rbind(p1, p2, p3)
################################################################
#Solving the Assignment Problem
answer <- lp.assign(final, direction = "min")
answer$solution
answer
str(answer)
answer <- lp.assign(final, direction = "min")
answer$solution
answer$objval
################################################################
#Importing Songs
setwd("~/Documents/Text Analysis of Quiero Adorar/Quiero-Adorar")
#Finding start of new songs
rm(list = ls())
song.v <- scan("Songs.txt", what = "character", sep = "\n")
song.position <- grep("^SONG:", song.v)
song.v[song.position]
#Adding a new line to songs to identify the end of the document.
song.v <- c(song.v, "END")
last.position <- length(song.v)
song.position <- c(song.position, last.position)
#Creating two lists to store results or raw frequencies and relative frequencies
song.raws.l <- list()
song.freqs.l <- list()
for(i in 1:length(song.position)){#initiates a for loop that iterates over song position
if (i != length(song.position)){#Stopping loop at end of document
#Preparing the Data
song.title <- song.v[song.position[i]] #Capturing the song title
start <- song.position[i] + 1 #Adding 1 to position to get first line of song
end <- song.position[i + 1] - 1#Getting last line of a song
#Similar to analysis done in first analysis 1. First Initial...
song.lines.v <- song.v[start:end]
song.words.v <- tolower(paste(song.lines.v, collapse = " "))
song.words.l <- strsplit(song.words.v, "\\W")
song.words.v <- unlist(song.words.l)
song.words.v <- song.words.v[which(song.words.v != "")]
#Removing commong sight words
#Removing sight words
not.sight.words <- which(song.words.v != "oh" &
song.words.v != "a" &
song.words.v != "tu" &
song.words.v != "you" &
song.words.v != "to" &
song.words.v != "de" &
song.words.v != "u" &
song.words.v != "que" &
song.words.v != "is" &
song.words.v != "my" &
song.words.v != "your" &
song.words.v != "ti" &
song.words.v != "we" &
song.words.v != "la" &
song.words.v != "coro" &
song.words.v != "en" &
song.words.v != "me" &
song.words.v != "mi" &
song.words.v != "y" &
song.words.v != "on" &
song.words.v != "the" &
song.words.v != "lo" &
song.words.v != "and" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "o" &
song.words.v != "verso" &
song.words.v != "has" &
song.words.v != "s" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "sofi" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "of" &
song.words.v != "it" &
song.words.v != "al" &
song.words.v != "un" &
song.words.v != "se" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "chorus")
song.words.v <- song.words.v[not.sight.words]
#Creating Frequency Tables
song.freqs.t <- table(song.words.v)
song.raws.l[[song.title]] <- song.freqs.t
song.freqs.t.rel <- 100*(song.freqs.t/sum(song.freqs.t))
song.freqs.l[[song.title]] <- song.freqs.t.rel
}
}
###################################################
#Begining of listwise analysis
#Applying the subset function to the relative frequency of a word in each song
quiero.l <- lapply(song.freqs.l, '[', 'quiero')
adorar.l <- lapply(song.freqs.l, '[', 'adorar')
#Rbinding all the list to get a matrix with all the data
quiero.m <- do.call(rbind,quiero.l)
adorar.m <- do.call(rbind,adorar.l)
#Pulling frequency vectors out to combine two frequencies
quiero.v <- quiero.m[,1]
adorar.v <- adorar.m[,1]
quiero.adorar.m <- cbind(quiero.v, adorar.v)
#Renaming columns above
colnames(quiero.adorar.m) <- c("quiero", "adorar")
#Creating a barplot of the two words
barplot(quiero.adorar.m, beside = TRUE, col = 'red')
#############################################
#Correlation Analysis
the.na.positions <- which(is.na(quiero.adorar.m))
the.na.positions
quiero.adorar.m[which(the.na.positions)] <- 0
quiero.adorar.m[the.na.positions] <- 0
quiero.adorar.m
cor(quiero.adorar.m)
cor.data.df <- as.data.frame(quiero.adorar.m)
cor(cor.data.df)
cor(sample(cor.data.df$quiero), cor.data.df$adorar)
mycors.v <- NULL
for (i in 1:10000){
mycors.v <- c(mycors.v, cor(sample(cor.data.df$quiero), cor.data.df$adorar))
}
hist(mycors)
hist(mycors.v)
hist(mycors.v, breaks = 100, col='red',
xlab="Correlation Coefficient",
main = "Histogram of Randmo Correlation Coefificien\n
with Normal Curve",
plot=TRUE)
xfit <- seq(min(mycors.v), max(mycors.v), length = 1000)
yfit <- dnorm(xfit, mean =m ean(mycors.v), sd = sd(mycors.v))
yfit <- dnorm(xfit, mean =mean(mycors.v), sd = sd(mycors.v))
yfit <- yfit*diff(h$mids[1:2])*length(mycors.v)
#Plotting the distribution
h <- hist(mycors.v, breaks = 100, col='red',
xlab="Correlation Coefficient",
main = "Histogram of Randmo Correlation Coefificien\n
with Normal Curve",
plot=TRUE)
xfit <- seq(min(mycors.v), max(mycors.v), length = 1000)
yfit <- dnorm(xfit, mean =mean(mycors.v), sd = sd(mycors.v))
yfit <- yfit*diff(h$mids[1:2])*length(mycors.v)
lines(xfit, yfit, col = "black", lwd=2)
################################################################
#Importing Songs
setwd("~/Documents/Text Analysis of Quiero Adorar/Quiero-Adorar")
#Finding start of new songs
rm(list = ls())
song.v <- scan("Songs.txt", what = "character", sep = "\n")
song.position <- grep("^SONG:", song.v)
song.v[song.position]
#Adding a new line to songs to identify the end of the document.
song.v <- c(song.v, "END")
last.position <- length(song.v)
song.position <- c(song.position, last.position)
#Creating two lists to store results or raw frequencies and relative frequencies
song.raws.l <- list()
song.freqs.l <- list()
for(i in 1:length(song.position)){#initiates a for loop that iterates over song position
if (i != length(song.position)){#Stopping loop at end of document
#Preparing the Data
song.title <- song.v[song.position[i]] #Capturing the song title
start <- song.position[i] + 1 #Adding 1 to position to get first line of song
end <- song.position[i + 1] - 1#Getting last line of a song
#Similar to analysis done in first analysis 1. First Initial...
song.lines.v <- song.v[start:end]
song.words.v <- tolower(paste(song.lines.v, collapse = " "))
song.words.l <- strsplit(song.words.v, "\\W")
song.words.v <- unlist(song.words.l)
song.words.v <- song.words.v[which(song.words.v != "")]
#Removing commong sight words
#Removing sight words
not.sight.words <- which(song.words.v != "oh" &
song.words.v != "a" &
song.words.v != "tu" &
song.words.v != "you" &
song.words.v != "to" &
song.words.v != "de" &
song.words.v != "u" &
song.words.v != "que" &
song.words.v != "is" &
song.words.v != "my" &
song.words.v != "your" &
song.words.v != "ti" &
song.words.v != "we" &
song.words.v != "la" &
song.words.v != "coro" &
song.words.v != "en" &
song.words.v != "me" &
song.words.v != "mi" &
song.words.v != "y" &
song.words.v != "on" &
song.words.v != "the" &
song.words.v != "lo" &
song.words.v != "and" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "o" &
song.words.v != "verso" &
song.words.v != "has" &
song.words.v != "s" &
song.words.v != "tú" &
song.words.v != "with" &
song.words.v != "sofi" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "of" &
song.words.v != "it" &
song.words.v != "al" &
song.words.v != "un" &
song.words.v != "se" &
song.words.v != "por" &
song.words.v != "for" &
song.words.v != "chorus")
song.words.v <- song.words.v[not.sight.words]
#Creating Frequency Tables
song.freqs.t <- table(song.words.v)
song.raws.l[[song.title]] <- song.freqs.t
song.freqs.t.rel <- 100*(song.freqs.t/sum(song.freqs.t))
song.freqs.l[[song.title]] <- song.freqs.t.rel
}
}
#######################################################
#Start of Measures of Lexical Variety
length(song.raws.l)
names(song.raws.l)
class(song.raws.l)
class(song.raws.l$`SONG: 1: OLOR FRAGANTE `)
song.raws.l[[1]]
str(song.raws.l)
sum(song.raws.l[[1]])/length(song.raws.l[[1]])
mean(song.raws.l[[1]])
lapply(song.raws.l, mean)
mean.word.use.m <- do.call(rbind, lapply(song.raws.l, mean))
mean.word.use.m
plot(mean.word.use.m type = 'h')
plot(mean.word.use.m ,type = 'h')
plot(scale(mean.word.use.m), type = 'h')
order(mean.word.use.m)
order(mean.word.use.m, decreasing = TRUE)
mean.word.use.m[order(mean.word.use.m, decreasing = TRUE)]
mean.word.use.m[order(mean.word.use.m, decreasing = TRUE),]
mean.word.use.m[order(mean.word.use.m, decreasing = TRUE),]
song.hapax.v <- sapply(song.raws.l, function(x) sum(x == 1))
song.hapax.v
song.hapax.v <- do.call(rbind,lapply(song.raws.l, sum))
#Counting words that only appear once a.k.a Hapax per song
song.hapax.v <- sapply(song.raws.l, function(x) sum(x == 1))
#length per song
song.length <- do.call(rbind,lapply(song.raws.l, sum))
hapax.percentages <- song.hapax.v/song.length
barplot(hapax.percentages, beside = T, col = 'red', names.arg = seq(1:length(song.raws.l)))
